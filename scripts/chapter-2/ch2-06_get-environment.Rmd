---
title: "ch2-environment"
author: "Kate Sheridan"
date: "`r Sys.Date()`"
output: html_document
---

to add; the extractions themselves from erddap.
right now it just loads in the extractions.

This script uses ERDDAP to extract sea surface temperature statistics from the dataset:
NOAA ERD and CoastWatch West Coast Regional Node
Multi-scale Ultra-high Resolution (MUR) SST Analysis fv04.1, Global, 0.01Â°, 2002-present,
Monthly

https://upwell.pfeg.noaa.gov/erddap/info/jplMURSST41mday/index.html

Then matches the sites to the downloaded raster for each year


```{r setup}
# needed to load data format
library(ncdf4)
# NOTE raster masks dplyr::select
library(raster)
library(rerddap)
library(tidyverse)
library(here)

# temperature data
erd_data <- here('rawdata', 'temp', 'erddap')
# eDNA
dataedna <- here('processeddata', 'peco', '2021-24_edna')
# for plots I don't think this makes plots? delete if not
#plot_out <- here('output', 'combined', 'ranges')

datefield = '20251212_'
```


# sst
2025-12-12 now this section is from previous ERDDAP extractions

setting up and testing the code for extractions below

```{r}
regions <- read_csv(here(dataedna, '20251113_peco_region-name-plotting.csv'))[-1] %>%
  rename(region_label = region_name_label) 

# load in and give headers
extracted_sst <- read_csv(here(erd_data, 'sitesstvalues', '20250713_sitesst_erddap_extract.csv'),
                          col_names = c('sst', 'filename', 'date', 'box_name', 
                                        'year', 'site_code', 'region_name', 
                                        'region_label', 'region_lat_name',
                                        'decimal_latitude', 'decimal_longitude')) %>%
  mutate(region_name = case_when(site_code == 'NC_WP' ~ 'CA_NC',
                                 TRUE ~ region_name)) %>%
  mutate(region_label = case_when(region_name == 'CA_NC' ~ 'Bodega Bay, California',
                                  region_label == 'San Fransisco Bay, California' ~ 'San Francisco Bay, California',
                                       TRUE ~ region_label)) %>%
  mutate(site_code = case_when(site_code == 'HB_SB' ~ 'HB_SR',
                               TRUE ~ site_code)) %>%
  mutate(decimal_latitude = case_when(site_code == 'HB_SR' ~ 40.77235,
                                      TRUE ~ decimal_latitude)) %>%
    mutate(decimal_longitude = case_when(site_code == 'HB_SR' ~ -124.2124,
                                      TRUE ~ decimal_longitude)) %>%
  distinct()

sst_summarystats <- extracted_sst %>%
  filter(year > 2020 & year < 2025) %>%
  group_by(site_code) %>%
  summarise(sst_max = max(sst),
            sst_min = min(sst),
            sst_median = median(sst),
            sst_mean = mean(sst),
            sst_sd = sd(sst),
            peco_temp95 = quantile(sst, probs = .95),
            peco_temp90 = quantile(sst, probs = .9),
            peco_temp75 = quantile(sst, probs = .75),
            peco_temp25 = quantile(sst, probs = .25),
            peco_temp10 = quantile(sst, probs = .1),
            peco_temp05 = quantile(sst, probs = .05)
            ) %>%
  left_join(regions) %>%
  dplyr::select(!c(samples, sites, avg_region_lat))

write_csv(sst_summarystats, here(erd_data, paste0(datefield, 'sitesst_peco_summarystats.csv')))

sst_by_regionyear <- extracted_sst %>%
  select(!c(filename, date, box_name)) %>%
  distinct() %>%
  group_by(region_name, year) %>%
  mutate(sst_max = max(sst),
         sst_min = min(sst),
            sst_median = median(sst),
            sst_mean = mean(sst),
            sst_sd = sd(sst),
            region_temp95 = quantile(sst, probs = .95),
            region_temp90 = quantile(sst, probs = .9),
            region_temp75 = quantile(sst, probs = .75),
            region_temp25 = quantile(sst, probs = .25),
            region_temp10 = quantile(sst, probs = .1),
            region_temp05 = quantile(sst, probs = .05)) %>%
  ungroup() %>%
  group_by(region_name) %>%
  mutate(avg_region_lat = mean(decimal_latitude)) %>%
  ungroup() %>%
  select(!c(site_code, sst, decimal_longitude, decimal_latitude)) %>%
  distinct() %>%
  arrange(region_lat_name)

write_csv(sst_by_regionyear, here(erd_data, paste0(datefield, 'mean-summer-sst_by-region.csv')))

sst_by_siteyear <- extracted_sst %>%
  select(!c(filename, date, box_name)) %>%
  distinct() %>%
  group_by(site_code, year) %>%
  summarise(sst_max = max(sst),
            sst_min = min(sst),
            sst_median = median(sst),
            sst_mean = mean(sst),
            sst_sd = sd(sst),
            site_temp95 = quantile(sst, probs = .95),
            site_temp90 = quantile(sst, probs = .9),
            site_temp75 = quantile(sst, probs = .75),
            site_temp25 = quantile(sst, probs = .25),
            site_temp10 = quantile(sst, probs = .1),
            site_temp05 = quantile(sst, probs = .05)
            ) %>%
  ungroup() %>%
  distinct() %>% 
  left_join(regions) %>%
  select(!c(region_code, region_code_label, samples, sites)) %>%
  arrange(region_lat_name)

write_csv(sst_by_siteyear, here(erd_data, paste0(datefield, 'summer-sst-summary-stats_by-site.csv')))
```

# ERDDAP extractions


## download

Previously this downloaded 10 years worth of temperature data. May not be necessary. 

ONLY if needed! Otherwise skip!
```{r download mursst monthly}
# This sends you to the webpage to see more
#browse('jplMURSST41mday')

# Lat, long, and time limits!
# extent of PECO study area
erd_lat <- c(25.7, 61.4)
erd_long <- c(-149.3, -110.3)
#erd_date <- c("2020-06-01", "2024-08-31")
erd_info <- info('jplMURSST41mday')

# extract by year
mursst_2020 <- griddap(erd_info, 
                       latitude = erd_lat, 
                       longitude = erd_long,
                       time = c("2020-06-01", "2020-08-31"),
                       fields = 'sst',
                       store = disk(path = here('rawdata', 'temp', 
                                                'erddap', 'byyear')),
                       read = FALSE
                       )

mursst_2021 <- griddap(erd_info, 
                       latitude = erd_lat, 
                       longitude = erd_long,
                       time = c("2021-06-01", "2021-08-31"),
                       fields = 'sst',
                       # store the ncf
                       store = disk(path = here('rawdata', 'temp', 
                                                'erddap', 'byyear')),
                       # don't immediately read it into R
                       read = FALSE
                       )

mursst_2022 <- griddap(erd_info, 
                       latitude = erd_lat, 
                       longitude = erd_long,
                       time = c("2022-06-01", "2022-08-31"),
                       fields = 'sst',
                       store = disk(path = here('rawdata', 'temp', 
                                                'erddap', 'byyear')),
                       read = FALSE
                       )


mursst_2023 <- griddap(erd_info, 
                       latitude = erd_lat, 
                       longitude = erd_long,
                       time = c("2023-06-01", "2023-08-31"),
                       fields = 'sst',
                       store = disk(path = here('rawdata', 'temp', 
                                                'erddap', 'byyear')),
                       read = FALSE
                       )

mursst_2024 <- griddap(erd_info, 
                       latitude = erd_lat, 
                       longitude = erd_long,
                       time = c("2024-06-01", "2024-08-31"),
                       fields = 'sst',
                       store = disk(path = here('rawdata', 'temp', 
                                                'erddap', 'byyear')),
                       read = FALSE
                       )
```
## calculate from ncs

To make the plots etc we need to have the means calculated
(from characterization).
Note the same query will always produce the same .nc file so these files should always match the download!

ONLY if the Rasters haven't been made yet! If you made the rasters, skip!

```{r seasonal values}
# load .ncs
sst20 = stack(here(erd_data, 'byyear', '254a8cfa4980b02f9f98dae96b4df820.nc'))
sst21 = stack(here(erd_data, 'byyear', 'c4276cb2ea408dc70a30e9c79a7852f3.nc'))
sst22 = stack(here(erd_data, 'byyear', '950ae2ef120fbcef9d1f06520478b21b.nc'))
sst23 = stack(here(erd_data, 'byyear', '035fd90558110819cc5bafd900e3ff58.nc'))
sst24 = stack(here(erd_data, 'byyear', '9860c440eb347a46766128ba25256a96.nc'))

# seasonal mean
# Compute overall mean and standard deviation

# 2020
sst20_overall_mean = mean(sst20, na.rm=T)
sst20_overall_sd = calc(sst20, sd, na.rm=T)
# 2021
sst21_overall_mean = mean(sst21, na.rm=T)
sst21_overall_sd = calc(sst21, sd, na.rm=T)
# 2022
sst22_overall_mean = mean(sst22, na.rm=T)
sst22_overall_sd = calc(sst22, sd, na.rm=T)
# 2023
sst23_overall_mean = mean(sst23, na.rm=T)
sst23_overall_sd = calc(sst23, sd, na.rm=T)
# 2024
sst24_overall_mean = mean(sst23, na.rm=T)
sst24_overall_sd = calc(sst23, sd, na.rm=T)


#save rasters
# 2020
writeRaster(sst20_overall_mean, here(erd_data, 'byyear', 'peco_jplmursst41_2020_summer-mean.tif'),
                         overwrite=T)
writeRaster(sst20_overall_sd, here(erd_data, 'byyear', 'peco_jplmursst41_2020_summer-sd.tif'), overwrite=T)
# 2021
writeRaster(sst21_overall_mean, here(erd_data, 'byyear', 'peco_jplmursst41_2021_summer-mean.tif'),
                         overwrite=T)
writeRaster(sst21_overall_sd, here(erd_data, 'byyear', 'peco_jplmursst41_2021_summer-sd.tif'), overwrite=T)
# 2022
writeRaster(sst22_overall_mean, here(erd_data, 'byyear', 'peco_jplmursst41_2022_summer-mean.tif'),
                         overwrite=T)
writeRaster(sst22_overall_sd, here(erd_data, 'byyear', 'peco_jplmursst41_2022_summer-sd.tif'), overwrite=T)
# 2023
writeRaster(sst23_overall_mean, here(erd_data, 'byyear', 'peco_jplmursst41_2023_summer-mean.tif'),
                         overwrite=T)
writeRaster(sst23_overall_sd, here(erd_data, 'byyear', 'peco_jplmursst41_2023_summer-sd.tif'), overwrite=T)
# 2024
writeRaster(sst24_overall_mean, here(erd_data, 'byyear', 'peco_jplmursst41_2024_summer-mean.tif'),
                         overwrite=T)
writeRaster(sst24_overall_sd, here(erd_data, 'byyear', 'peco_jplmursst41_2024_summer-sd.tif'), overwrite=T)

```

# characterize sites

Need a lat and long for each site; getting from metadata combined, but adding the "nicer" stuff and precalculated lats from the plot df. *edit* actually splitting oregon means we recalculate region_latitude so if we don't split oregon, use the pre-calculated stuff.

We'll characterize the sites for every year regardless of if they were sampled and filter in analysis if needed.
```{r}
regions <- read_csv(here(dataedna,
                         '20251113_peco_region-name-plotting.csv'))[-1] 

# region-based lats and longs
by_region <- regions %>%
  group_by(region_code) %>%
  # already in this one
  #mutate(avg_region_lat = mean(decimal_latitude)) %>%
  mutate(avg_region_long = mean(decimal_longitude)) %>%
  ungroup() %>%
  dplyr::select(!c(site_code, decimal_longitude, decimal_latitude)) %>%
  distinct()

# site based lats and longs
# Note this isn't really different from 'regions' but 
# the code is set up to take this dataframe so lets just keep it
by_site <- regions %>%
  dplyr::select(!avg_region_lat) %>%
  group_by(site_code) %>%
  mutate(avg_site_lat = decimal_latitude) %>%
  mutate(avg_site_long = decimal_longitude) %>%
  ungroup() %>%
  dplyr::select(!c(decimal_latitude, decimal_longitude)) %>%
  distinct()
```

Now that the sites and regions are listed we'll extract the relevant info from the rasters. 
## By region
```{r extract rasters region}
# set up the df to be in the required format
region_to_extract <- by_region %>%
  column_to_rownames('region_code') %>%
  # longitude comes first for whatever reason
  #relocate(avg_region_long, avg_region_lat) %>%
  dplyr::select(avg_region_long, avg_region_lat)

# Next, we load all the environmental variables that will be used for the extraction procedure.  
# We create a list containing all the rasters either describing a mean or a standard deviation: 
rasterList = list('sst20_summer_mean_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2020_summer-mean.tif'),
                'sst20_summer_sd_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2020_summer-sd.tif'),
                'sst21_summer_mean_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2021_summer-mean.tif'),
                'sst21_summer_sd_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2021_summer-sd.tif'),
                'sst22_summer_mean_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2022_summer-mean.tif'),
                'sst22_summer_sd_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2022_summer-sd.tif'),
                'sst23_summer_mean_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2023_summer-mean.tif'),
                'sst23_summer_sd_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2023_summer-sd.tif'),
                'sst24_summer_mean_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2024_summer-mean.tif'),
                'sst24_summer_sd_c'=raster('rawdata/temp/erddap/byyear/peco_jplmursst41_2024_summer-sd.tif'))

# extract mean with 20km buffer
# Note `extract` is in base R also so specify `raster::`
#raster::extract(rasterList$sst21_summer_mean, region_to_extract, 
#        buffer=20000, 
#        fun=mean, na.rm=T)

# for regions we want to extract 20 km around all of them so it is comparable
region_values <- lapply(rasterList, function(ras20km){
  region_value <- raster::extract(ras20km, region_to_extract, buffer=20000, fun=mean, na.rm=T)
  return(region_value)
})

region_matrix <- as.data.frame(region_values)

# Add the identifiers of each sampling location as rowname. 
rownames(region_matrix) = rownames(region_to_extract)
```

### prep to save
```{r}
region_matrix_ready = region_matrix %>%
  rownames_to_column('region_code') %>%
  left_join(by_region) %>%
  dplyr::select(!avg_region_long) %>%
  relocate(region_name, region_lat_name, region_code_label, avg_region_lat) %>%
  group_by(region_code) %>%
  # last 5 years
  mutate(mean_5yr_region = mean(c(sst20_summer_mean_c, sst21_summer_mean_c,
                            sst22_summer_mean_c, sst23_summer_mean_c,
                            sst24_summer_mean_c))) %>%
  ungroup()

write_csv(region_matrix_ready, here(dataedna,
                                    paste0(datefield,'environment_region.csv')))
```

## by site

note: vancouver island still missing temps

```{r extract rasters region}
# set up the df to be in the required format
sites_to_extract <- by_site %>%
  column_to_rownames('site_code') %>%
  # longitude comes first for whatever reason
  select(avg_site_long, avg_site_lat) 

# Next, we load all the environmental variables that will be used for the extraction procedure.  
# We create a list containing all the rasters either describing a mean or a standard deviation: 
# use rasterlist from above
#rasterList = list()


# for sites we want to extract 20 km around only sites with NAs them , so we will use the code from physalia
site_values <- lapply(rasterList, function(ras){
  
  # Here below we define the function to apply to each element of the raster list (ras = a raster of a specific environmental variable)
  # The function is composed of two steps: 
  # 1) We extract the values at the exact coordinates of the sampling site.
  # 2) If there are missing values, we extract the value on a buffer of 20km radius around the coordinates of the sampling site.
  
  # First part:  extract the values at the sampling site coordinate
  point_val = raster::extract(ras, sites_to_extract) 
  
  # Second part: check if there are missing values...
  if (sum(is.na(point_val))>0) {    # if there are missing values...
    missing_ss = which(is.na(point_val)) # find which sampling sites are missing
    point_val_AV = raster::extract(ras, sites_to_extract[missing_ss,,drop=F], buf=20000, fun=mean, na.rm=T) # extract values for missing sites using the buffer (nb: the "drop=F" option ensures that even if there is only one point to extract, long and lat are kept in a "matrix set-up")
    point_val[missing_ss] = point_val_AV # replace missing values with those calculated using the buffer
  }
   
  # end of function: return the point values 
  return(point_val)
})

site_matrix <- as.data.frame(site_values)

# Add the identifiers of each sampling location as rowname. 
rownames(site_matrix) = rownames(sites_to_extract)
```

### prep to save
```{r}
site_matrix_ready = site_matrix %>%
  rownames_to_column('site_code') %>%
  left_join(by_site) %>%
  dplyr::select(!avg_site_long) %>%
  relocate(site_code, region_name, region_lat_name, 
           region_code_label, avg_site_lat) %>%
  group_by(site_code) %>%
    mutate(mean_5yr_site = mean(c(sst20_summer_mean_c, sst21_summer_mean_c,
                            sst22_summer_mean_c, sst23_summer_mean_c,
                            sst24_summer_mean_c))) %>%
  ungroup()

write_csv(site_matrix_ready, here(dataedna,
                                    paste0(datefield, 'environment_site.csv')))
```


